key,module,text,url
import_data,preprocessing,"Import images and videos from a directory. Imported files are added to the thumbnail list.", /offline-modules/#supported-file-formats
image_options,preprocessing,"Image options for preprocessing.\nResize Mode: Method to resize images to target resolution.\nResolution: Target resolution for processed images.\nNon-square Framing: Enable non-square aspect ratios for processed images.\nAspect Ratio: The ratio between width and height dimensions.\nPadding Options: Padding method for non-square images.", /offline-modules/#data-preparation
fps_video_extraction,preprocessing,"Frame rate for extracting frames from video files.\nHigher FPS will extract more frames but take longer."
resize_mode,preprocessing,"Method to resize images to target resolution.\nstretch - Stretches image to fit\ncenter crop - Crops from center to fit"
resolution,preprocessing,"Target resolution for processed images.\nUse +/- buttons to adjust. Images will be resized to this resolution."
non_square_framing,preprocessing,"Enable non-square aspect ratios for processed images."
aspect_ratio,preprocessing,"The ratio between width and height dimensions.\nSet custom width and height ratios to create non-square images."
padding_options,preprocessing,"Padding method for non-square images.\nblack - Black padding\nwhite - White padding\nbleeding - Extend edge pixels"
augmentation,preprocessing,"Applies data augmentation during processing to increase dataset diversity. Use cautiously for orientation-sensitive data.\nX-Flip: Flip images horizontally (left-right).\nY-Flip: Flip images vertically (up-down)."
folder_name,preprocessing,"Name for the output folder. The resolution suffix will be automatically added (e.g., dataset_512x512)."

data_preprocessing,training,"Create a dataset from your data for training. The data preparation module allows for more preprocessing options. Use the quick data preparation tool to quickly prepare a dataset.\nData Path: All supported media within this directory will be imported automatically. Supported formats: Image/Video folder and ZIP archive\nResize Mode: Method to resize images. stretch - Stretch to target size, center crop - Center crop\nResolution: Target resolution for processed images. Use +/- buttons to adjust. Images will be resized to this resolution.\nFPS for Video Extraction: Frame rate for extracting frames from video files. Higher FPS will extract more frames but take longer.\nFolder Name: Name for the output folder. The resolution suffix will be automatically added (e.g. dataset_512x512).", /offline-modules/#data-preparation
fps_video_extraction,training,"Frame rate used to extract frames from video files in the data path.\nHigher values extract more frames but take longer."
resolution_training,training,"Target resolution for processed images.\nUse +/- buttons to adjust. Images will be resized to this resolution."
resize_mode_training,training,"Method to resize images:\nstretch - Stretch to target size\ncenter crop - Center crop"
folder_name_training,training,"Name for the output folder.\nThe resolution suffix will be automatically added (e.g., dataset_512x512)."
preprocessing_data_path,training,"Path to data used for dataset creation.\nSupported formats:\n- Image folder\n- ZIP archive\n- Video file (.mp4/.avi)"

training_module,training,"Perform model training on your dataset. Ensure you have prepared a dataset from the data preparation modulebefore training.\nSave Path: Model checkpoints and generated images will be saved here during training\nResume Pkl: Model checkpoint file (.pkl) to resume training. Leave empty to start from scratch\nTraining Augmentation: In-training data augmentation method to improve training stability on smaller datasets. ADA - Adaptive Discriminator Augmentation, DiffAUG - Differential Augmentation\nAugmentation Pipeline: Specific configuration of the data augmentation pipeline. Different augmentation methods have different options\nBatch Size: Number of images per training batch. Larger batches require more VRAM\nConfiguration: Preset training configurations. auto - Automatic configuration, stylegan2 - Standard StyleGAN2, paper256/512/1024 - Paper configurations, cifar - CIFAR dataset configuration\nAdvanced Options: Generator LR - Generator learning rate, Discriminator LR - Discriminator learning rate, Gamma - Training stability parameter, Snapshot - Checkpoint saving interval",/offline-modules/#training
save_path_training,training,"Path to save training results\nModel checkpoints and generated images will be saved here during training"
data_path_training,training,"Path to the training dataset."
resume_pkl_training,training,"Model checkpoint file (.pkl) to resume training\nLeave empty to start from scratch"
augmentation_training,training,"In-training data augmentation method.\nImprove training stability on smaller datasets.\nADA - Adaptive Discriminator Augmentation\nDiffAUG - Differential Augmentation"
training_augmentation_guide,training,,/training-aug/
aug_pipeline_training,training,"Specific configuration of the data augmentation pipeline\nDifferent augmentation methods have different options",/offline-modules/#training
batch_size_training,training,"Number of images per training batch\nLarger batches require more VRAM"
config_training,training,"Preset training configurations:\nauto - Automatic configuration\nstylegan2 - Standard StyleGAN2\npaper256/512/1024 - Paper configurations\ncifar - CIFAR dataset configuration"
advanced_training,training,"Advanced training options:\nGenerator LR - Generator learning rate\nDiscriminator LR - Discriminator learning rate\nGamma - Training stability parameter\nSnapshot - Checkpoint saving interval\nMirror - Horizontal flip of dataset"
generator_lr_training,training,"Learning rate for the generator network"
discriminator_lr_training,training,"Learning rate for the discriminator network"
gamma_training,training,"Training stability parameter"
snapshot_training,training,"Checkpoints saving interval"

projection_module,projection,"Project a target image, text prompt, or both to find the closest latent vector of a trained model.\nNetwork Path: Path to the trained StyleGAN2 model (.pkl file)\nTarget Image: Image to project into the latent space\nTarget Text: Text description to guide the projection (optional)\nOutput Directory: Directory to save projection results\nSave Video: Save the projection process as a video\nSeed: Random seed for reproducibility\nLearning Rate: Learning rate for optimization\nSteps: Number of optimization steps\nUse VGG: Use VGG perceptual loss\nUse CLIP: Use CLIP-based semantic guidance\nUse Pixel: Use pixel-wise loss\nUse Penalty: Apply regularization penalty\nUse Center: Center the latent code initialization",/offline-modules/#projection-module
network_path_projection,projection,"Path to the trained StyleGAN2 model (.pkl file)"
target_image_projection,projection,"Image to project into the latent space"
target_text_projection,projection,"Text description to guide the projection (optional)"
output_dir_projection,projection,"Directory to save projection results"
save_video_projection,projection,"Save the projection process as a video"
seed_projection,projection,"Random seed for reproducibility"
learning_rate_projection,projection,"Learning rate for optimization"
steps_projection,projection,"Number of optimization steps"
use_vgg_projection,projection,"Use VGG perceptual loss"
use_clip_projection,projection,"Use CLIP-based semantic guidance"
use_pixel_projection,projection,"Use pixel-wise loss"
use_penalty_projection,projection,"Apply regularization penalty"
use_center_projection,projection,"Center the latent code initialization"

pca_module,pca,"Identify and extracts interpretable feature directions in the latent space of a trained model.\nNetwork Path: Path to the trained StyleGAN2 model (.pkl file)\nPCA Estimator: PCA estimation method to use (pca/ipca/fbpca/ica/spca)\nFeatures: Number of principal components to extract\nSparsity: Sparsity parameter for sparse PCA\nSave Path: Directory to save extracted features", /offline-modules/#ganspace
pkl_path_pca,pca,"Path to the trained StyleGAN2 model (.pkl file)"
pca_mode_pca,pca,"PCA estimation method to use (pca/ipca/fbpca/ica/spca)"
num_features_pca,pca,"Number of principal components to extract"
alpha_pca,pca,"Sparsity parameter for sparse PCA"

super_res_module,super_res,"Upscale images and videos for higher resolution.\nModel: Model type. Quality (best quality, slowest), Balance (balanced), Fast (fastest)\nScale Mode: Choose between custom resolution or scale factor\nScale Factor: Scale factor for output resolution\nWidth: Custom output width in pixels\nHeight: Custom output height in pixels\nSharpening: Additional sharpening strength (1 = normal, higher = sharper)\nSave Path: Directory to save enhanced results", /offline-modules/#super-resolution
input_path_super_res,super_res,"Input image or video files to enhance"
model_type_super_res,super_res,"Model type: Quality (best quality, slowest), Balance (balanced), Fast (fastest)"
scale_mode_super_res,super_res,"Choose between custom resolution or scale factor"
scale_factor_super_res,super_res,"Scale factor for output resolution"
width_super_res,super_res,"Custom output width in pixels"
height_super_res,super_res,"Custom output height in pixels"
sharpening_super_res,super_res,"Additional sharpening strength (1 = normal, higher = sharper)"

network_mixing_module,network_mixing,"Mix two trained models to make a new model.\nOutput Name: Name for the combined model\nResolution Layers: Layer groups by resolution\nModel Selection: Select which model's weights to use for each layer\nRecover: Restore previous layer settings\nDisable: Disable layers from this point", /offline-modules/#model-mixing
model1_network_mixing,network_mixing,"First model to mix from"
model2_network_mixing,network_mixing,"Second model to mix from"
output_name_network_mixing,network_mixing,"Name for the combined model"
resolution_layers_network_mixing,network_mixing,"Layer groups by resolution"
model_selection_network_mixing,network_mixing,"Select which model's weights to use for each layer"
recover_network_mixing,network_mixing,"Restore previous layer settings"
disable_network_mixing,network_mixing,"Disable layers from this point"

network_latent,visualizer,"Network & latent settings for controlling the model and latent space", /live-module/#network-and-latent
diversity_noise,visualizer,"Controls for diversity and noise generation.\nDiversity: Controls image variation. 0 produces the same image every time, values around 0.8â€“1.0 balance diversity and dataset fidelity.\nNoise: Toggles noise on or off. Disabling noise results in smoother images with fewer textures.\nGlobal Noise: Adjusts the overall strength of noise applied to the image.\nNoise Seed: Sets the noise seed to change texture while keeping the same image structure.\nAnim: Animates noise by changing the noise seed every frame.", /live-module/#diversity-and-noise
looping,visualizer,"Settings for creating animation loops", /live-module/#looping  
performance_osc,visualizer,"Performance settings and OSC communication options", /live-module/#performance-and-osc
adjust_input,visualizer,"Tools for adjusting input parameters", /live-module/#adjust-input
layer_transform,visualizer,"Controls for layer-wise transformations", /live-module/#layer-transformations
model_mixing,visualizer,"Settings for mixing multiple models", /live-module/#model-mixing-real-time
presets,visualizer,"Save and load parameter presets", /live-module/#presets
audio,visualizer,"Audio input and visualization settings"